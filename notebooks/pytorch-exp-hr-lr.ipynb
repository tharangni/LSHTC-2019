{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import heapq\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from scripts.src.hierarchy import *\n",
    "from scripts.src.processing import *\n",
    "from scripts.src.label_utils import *\n",
    "from scripts.src.data_reading import *\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "logging.basicConfig(level=logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and num_gpus > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_data(y):\n",
    "\n",
    "    class_labels = np.unique(y)\n",
    "    num_tasks = len(class_labels)\n",
    "    num_examples = y.shape[0]\n",
    "    if num_tasks == 1:\n",
    "        raise ValueError(\"The number of classes has to be greater than one.\")\n",
    "    elif num_tasks == 2:\n",
    "        if 1 in class_labels and -1 in class_labels:\n",
    "            num_tasks = 1\n",
    "            class_labels = np.array([-1, 1])\n",
    "        elif 1 in class_labels and 0 in class_labels:\n",
    "            num_tasks = 1\n",
    "            class_labels = np.array([0, 1])\n",
    "        else:\n",
    "            raise ValueError(\"Unable to decide postive label\")\n",
    "\n",
    "    lbin = LabelBinarizer(neg_label=-1, pos_label=1)\n",
    "    lbin.fit(class_labels)\n",
    "    y_bin = lbin.transform(y)\n",
    "    return y_bin, class_labels, num_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    def __init__(self, datafile, catfile, subsample, is_directed, fmt, split):\n",
    "        self.datafile = datafile\n",
    "        \n",
    "        if fmt == \"libsvm\":\n",
    "            self.lib_data = LIBSVM_Reader(self.datafile, True, n_components, subsample, split)\n",
    "            self.df = self.lib_data.data_df\n",
    "            self.MLmatrix = self.lib_data.label_matrix\n",
    "            self.MLbin = self.lib_data.binarizer\n",
    "            self.rev_df = self.lib_data.rev_df\n",
    "            \n",
    "        elif fmt ==\"raw\":\n",
    "            # TODO: add split here too\n",
    "            self.raw_df = CSV_Reader(self.datafile, subsample)\n",
    "            self.df = self.raw_df.data_df\n",
    "            self.rev_df = self.raw_df.rev_df\n",
    "        \n",
    "        self.cat = HierarchyUtils(catfile, n_components, is_directed, False)\n",
    "#         self.wn = self.cat.generate_vectors(device = device, neighbours = True)\n",
    "\n",
    "    def read_df(self, idx):\n",
    "        i = self.df.index[self.df[\"doc_id\"] == idx][0]\n",
    "        return self.df.at[i, \"doc_vector\"], self.df.at[i, \"doc_labels\"], i\n",
    "    \n",
    "    def __getitem__(self, _id):\n",
    "        return self.read_df(_id)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _id in self.df.index:\n",
    "            yield self[_id]\n",
    "\n",
    "class DatasetModule(Dataset):\n",
    "\n",
    "    def __init__(self, root_location, cat_file, subsample, is_directed, fmt, split):\n",
    "        \n",
    "        self.iter = DatasetIterator(root_location, cat_file, subsample, is_directed, fmt, split)\n",
    "\n",
    "        self.small_mapper = self.iter.cat.node2id\n",
    "\n",
    "    def encode_labels(self, labels, idx):\n",
    "        y = np.zeros(len(self.small_mapper), dtype=np.float32)\n",
    "        y_in = np.ones((len(self.small_mapper),))*-1\n",
    "        for each_label in labels:\n",
    "            y[self.small_mapper[each_label]] = 1\n",
    "            y_in[self.small_mapper[each_label]] = 1\n",
    "        y = torch.from_numpy(y)\n",
    "        y_in = torch.as_tensor(y_in, dtype=torch.float32, device=device)\n",
    "        return y_in, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.iter.df)\n",
    "\n",
    "    def __load(self, idx):\n",
    "        doc_vec, doc_labels, doc_id = self.iter[idx]\n",
    "        yin, y01 = self.encode_labels(doc_labels, idx)\n",
    "        return doc_vec, doc_labels, yin, y01\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.__load(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_labels(train_data, y_true, y_pred):\n",
    "    # label_vector -> label_id (per instance)\n",
    "    # always wrt training data\n",
    "    # MLbinarizer should do it correctly\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 394756/394756 [00:10<00:00, 39085.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 394756/394756 [00:03<00:00, 102699.37it/s]\n",
      "35437it [00:00, 312770.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = DatasetModule(\"../DMOZ/train.txt\", \"../DMOZ/cat_hier.txt\", False, True, \"libsvm\", \"test\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data = DatasetModule(\"../rcv1.tar/RCV1_1/rcv1.test.ltc.svm\", \"../rcv1.tar/RCV1_1/rcv1.topic.hierarchy\", 0.1, False, \"libsvm\", \"test\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data = DatasetModule(\"../swiki/data/train_remapped.txt\", \"../swiki/data/cat_hier.txt\", False, True, \"libsvm\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data = DatasetModule(\"../swiki/data/test_remapped.txt\", \"../swiki/data/cat_hier.txt\", False, False, \"libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "batch size affects performance. higher batch size(99) vs. lower(40) for rcv1 didn't converge properly while training\n",
    "'''\n",
    "\n",
    "batch_size = 8\n",
    "validation_split = .1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, sampler = train_sampler)\n",
    "validation_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20835"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "doc_vec, labels, yin, y01 =  train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300])\n",
      "**************************************************\n",
      "[tensor([10]), tensor([11]), tensor([34])]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "torch.Size([1, 101])\n",
      "--------------------------------------------------\n",
      "torch.Size([1, 101])\n",
      "__________________________________________________\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "print(doc_vec.shape)\n",
    "print(\"*\"*50)\n",
    "print(labels)\n",
    "print(\"~\"*50)\n",
    "print(yin.shape)\n",
    "print(\"-\"*50)\n",
    "print(y01.shape)\n",
    "print(\"_\"*50)\n",
    "# print(_id.shape)\n",
    "print(\"^\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda\n",
    "torch.backends.cudnn.version()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model regularization: wn -> should regularize towards w_pi. i.e. minimize their distance. else it'll regularize towards a random no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRLoss(nn.Module):\n",
    "    def __init__(self, n_node):\n",
    "        super().__init__()\n",
    "        self.n_node = n_node\n",
    "        self.H = train_data.iter.cat\n",
    "        self.pi = self.H.hier_obj.neighbors(self.n_node)\n",
    "        \n",
    "    def forward(self, W):\n",
    "        w_n, w_pi = W[:, self.n_node], W[:, self.pi]\n",
    "        param = torch.norm(w_n.view(-1,1) - w_pi, 2, dim=1)\n",
    "        W[:, self.n_node] = param\n",
    "\n",
    "        param = 0.5*param**2\n",
    "        norm_sq = param.sum()\n",
    "        return norm_sq\n",
    "    \n",
    "    def non_leaf_update(self, W):\n",
    "        Cn = self.H.parent2child_table[self.n_node]\n",
    "        neighbors = self.H.hier_obj.neighbors(self.n_node)\n",
    "        \n",
    "        W[:, self.n_node] = (1/(len(Cn)+1)) * (torch.sum(W[:, neighbors], dim=1))\n",
    "        return W\n",
    "\n",
    "class Node(nn.Module):\n",
    "    def __init__(self, weight_dims):\n",
    "        super().__init__()\n",
    "        w_n = torch.FloatTensor(*weight_dims)\n",
    "        weights_n = nn.init.xavier_normal_(w_n)\n",
    "        \n",
    "        self.weight = nn.Parameter(weights_n)    \n",
    "        \n",
    "    def forward(self, x_i):\n",
    "        out = x_i.matmul(self.weight)\n",
    "        return out\n",
    "    \n",
    "class HRLR(nn.Module):\n",
    "    def __init__(self, d_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = Node([d_dim, num_classes])\n",
    "\n",
    "    def forward(self, yin, x_i):\n",
    "        score = self.linear.forward(x_i)\n",
    "        self.fwd_pass = yin * score\n",
    "        return score\n",
    "    \n",
    "    def compute_loss_leaf(self):\n",
    "        loss = torch.log2(1+torch.exp(-self.fwd_pass))\n",
    "        value = loss.sum()\n",
    "        return value\n",
    "    \n",
    "    def compute_non_leaf_loss(self, k):\n",
    "        self.linear.non_leaf_update(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_state(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    num_epochs = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    return model, optimizer, num_epochs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_state(model, optimizer, num_epochs, loss, path):\n",
    "    torch.save({\n",
    "            'epoch': num_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model():\n",
    "    '''\n",
    "    training performance is affected by large `n_tasks` size which basically increases the number of parameters to tune.\n",
    "    as parameter dimension increases, weight decay also needs to be increased. what is the relation between param dim \n",
    "    and weight decay?\n",
    "    '''\n",
    "\n",
    "    # Hyper Parameters \n",
    "    d_dim = n_components\n",
    "    num_epochs = 2\n",
    "    learning_rate = 0.001\n",
    "    num_classes = len(train_data.iter.MLbin.classes_) #batch_size\n",
    "\n",
    "    model = HRLR(d_dim, num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS(params=model.parameters(), max_iter=2)\n",
    "    \n",
    "    return model, optimizer, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, num_epochs = reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 101])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20835"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = {\n",
    "    \"test_error\": [],\n",
    "    \"train_error\": [],\n",
    "    \"valid_error\": [],\n",
    "    \"loss\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0925,  0.0017,  0.0396,  ..., -0.0151, -0.0114,  0.0708],\n",
       "                      [ 0.0531,  0.0605,  0.0041,  ...,  0.0661,  0.0218,  0.0909],\n",
       "                      [ 0.0855,  0.0400,  0.0825,  ..., -0.1574, -0.0318,  0.1835],\n",
       "                      ...,\n",
       "                      [-0.0028,  0.1018, -0.0475,  ..., -0.0889, -0.0811, -0.0640],\n",
       "                      [ 0.0216,  0.0916, -0.0177,  ...,  0.0823, -0.0198, -0.0527],\n",
       "                      [ 0.0443,  0.0321, -0.0023,  ..., -0.0274, -0.0599, -0.1014]]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/20835 [00:00<?, ?it/s]INFO:root:oh we got some nans...!\n",
      "  0%|                                                                                | 9/20835 [00:00<04:08, 83.89it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|                                                                               | 20/20835 [00:00<03:54, 88.73it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|                                                                               | 30/20835 [00:00<03:47, 91.51it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▏                                                                              | 42/20835 [00:00<03:38, 94.95it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▏                                                                              | 53/20835 [00:00<03:32, 97.88it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▏                                                                              | 63/20835 [00:00<03:32, 97.85it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▎                                                                              | 72/20835 [00:00<03:38, 94.97it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▎                                                                             | 84/20835 [00:00<03:25, 100.99it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  0%|▎                                                                             | 97/20835 [00:00<03:14, 106.56it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▍                                                                            | 111/20835 [00:01<03:08, 109.84it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▍                                                                            | 124/20835 [00:01<03:01, 114.20it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▌                                                                            | 136/20835 [00:01<03:23, 101.89it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▌                                                                            | 149/20835 [00:01<03:09, 108.89it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▌                                                                            | 161/20835 [00:01<03:09, 109.16it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▋                                                                            | 173/20835 [00:01<03:06, 110.56it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▋                                                                            | 185/20835 [00:01<03:09, 109.12it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▋                                                                            | 197/20835 [00:01<03:10, 108.14it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▊                                                                            | 210/20835 [00:01<03:06, 110.32it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▊                                                                            | 222/20835 [00:02<03:12, 106.92it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▊                                                                            | 234/20835 [00:02<03:11, 107.76it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▉                                                                            | 246/20835 [00:02<03:07, 109.56it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|▉                                                                            | 259/20835 [00:02<03:00, 113.99it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|█                                                                            | 271/20835 [00:02<03:05, 111.13it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|█                                                                            | 283/20835 [00:02<03:15, 104.90it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|█                                                                            | 296/20835 [00:02<03:06, 110.14it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  1%|█▏                                                                           | 308/20835 [00:02<03:02, 112.52it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  2%|█▏                                                                           | 320/20835 [00:02<02:59, 114.25it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  2%|█▏                                                                           | 333/20835 [00:03<03:01, 113.20it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  2%|█▎                                                                           | 345/20835 [00:03<03:07, 109.39it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  2%|█▎                                                                           | 357/20835 [00:03<03:17, 103.81it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n",
      "  2%|█▎                                                                           | 370/20835 [00:03<03:08, 108.75it/s]INFO:root:oh we got some nans...!\n",
      "INFO:root:oh we got some nans...!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-49fe2ecd59b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#         model.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdoc_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my01\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mai\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mai\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# path = \"../saved_models/rcv1-state_lr-0.001_bs-32_lmbda-0.0002441567194182426.pth\"\n",
    "path = \"../saved_models/rcv1-state_lr-{}_bs-{}.pth\".format(1e-3, batch_size)\n",
    "\n",
    "leaves = train_data.iter.cat.T_leaves\n",
    "node2id = train_data.small_mapper\n",
    "classes = list(node2id.values())\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "#     if os.path.isfile(path):\n",
    "#         model, optimizer, i, monitor[\"loss\"] = load_model_state(path)\n",
    "#         model.to(device)\n",
    "\n",
    "    for j, (doc_vec, labels, yin, y01) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        if torch.isnan(list(model.parameters())[0].data.sum()):\n",
    "            logging.info(\"oh we got some nans...!\")\n",
    "            model, optimizer, num_epochs = reset_model()\n",
    "        else: \n",
    "            for kk in labels:\n",
    "                k = node2id[kk]\n",
    "                rr = RRLoss(k)\n",
    "\n",
    "                if kk not in leaves:\n",
    "                    for name, param in state_dict.items():\n",
    "                        param_ = rr.non_leaf_update(param)\n",
    "                        state_dict[name].copy_(param_)\n",
    "                else: \n",
    "                    def closure():\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model.forward(yin, doc_vec)\n",
    "                        loss = model.compute_loss_leaf()\n",
    "\n",
    "                        for name, param in state_dict.items():\n",
    "                            L2_reg = rr.forward(param)\n",
    "                            loss.add_(L2_reg)\n",
    "\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        monitor[\"loss\"].append(loss)\n",
    "                        return loss\n",
    "                    optimizer.step(closure)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                           | 370/20835 [00:19<03:08, 108.75it/s]"
     ]
    }
   ],
   "source": [
    "plt.plot(monitor[\"loss\"]); #with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_state(model, optimizer, num_epochs, monitor[\"loss\"], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def y_predict(data, model, k):\n",
    "    logging.info(\"Predicting for training model...\")\n",
    "    with torch.no_grad():\n",
    "        y_t = []\n",
    "        y_p = []\n",
    "        for index, (doc_vec, labs, yin, y01) in enumerate(tqdm(data)):\n",
    "            # do softmax on the output layer. then sort the indices. or like consider the scores of only\n",
    "            # the top k indices. convert these to 1s and the rest to 0s. run eval after performing this \n",
    "            # conversion.\n",
    "            score = model.linear.forward(doc_vec)\n",
    "            y_true = y01.numpy()\n",
    "            \n",
    "            softmax_op = F.softmax(score)\n",
    "            softmax_op = softmax_op.numpy() \n",
    "            r = np.zeros_like(softmax_op)\n",
    "            \n",
    "#             if y_true.shape != softmax_op.shape:\n",
    "#                 pad_x = abs(softmax_op.shape[0] - y_true.shape[0])\n",
    "#                 pad_y = abs(softmax_op.shape[1] - y_true.shape[1])\n",
    "#                 y_true = np.pad(y_true, [(0, pad_x), (0,0)], \"constant\")\n",
    "                \n",
    "            for each_row in range(len(softmax_op)):\n",
    "#                 k = np.random.randint(2, k+1)\n",
    "                k = np.sum(y_true[each_row]).astype(int)\n",
    "                row_score_list = softmax_op[each_row].tolist()\n",
    "                max_idx = list(map(row_score_list.index, heapq.nlargest(k, row_score_list)))\n",
    "                r[each_row][max_idx] = 1\n",
    "\n",
    "            y_t.append(y_true)\n",
    "            y_p.append(r)\n",
    "\n",
    "    yt = np.vstack(y_t)\n",
    "    yp = np.vstack(y_p)\n",
    "    \n",
    "#     if yt.shape != yp.shape:\n",
    "#         pad_x = abs(yp.shape[0] - yt.shape[0])\n",
    "#         pad_y = abs(yp.shape[1] - yt.shape[1])\n",
    "#         yt = np.pad(yt, [(0, pad_x), (0,0)], \"constant\")\n",
    "    \n",
    "    return yt, yp\n",
    "\n",
    "# yt_, yp_ = y_predict(train_loader, model, 6)\n",
    "\n",
    "# fscore per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Predicting for training model...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2314/2314 [00:06<00:00, 364.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        17\n",
      "           1       0.84      0.33      0.47      1083\n",
      "           2       0.52      0.31      0.39       331\n",
      "           3       0.25      0.27      0.26       697\n",
      "           4       0.38      0.57      0.45       606\n",
      "           5       0.86      0.18      0.30       426\n",
      "           6       0.00      0.00      0.00        38\n",
      "           7       0.80      0.73      0.76       221\n",
      "           8       0.83      0.20      0.32       220\n",
      "           9       0.00      0.00      0.00        75\n",
      "          10       0.26      0.83      0.40        35\n",
      "          11       0.17      0.01      0.02       122\n",
      "          12       0.32      0.90      0.47        48\n",
      "          13       0.65      0.56      0.60        27\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.70      0.81      0.75        26\n",
      "          16       0.26      0.03      0.06       145\n",
      "          17       0.33      0.01      0.02        91\n",
      "          18       0.25      0.98      0.40       126\n",
      "          19       0.00      0.00      0.00        11\n",
      "          20       0.45      0.53      0.49        17\n",
      "          21       0.29      0.02      0.04       104\n",
      "          22       0.45      0.62      0.53        16\n",
      "          23       0.23      0.57      0.32        23\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00        43\n",
      "          26       0.00      0.00      0.00         3\n",
      "          27       0.00      0.00      0.00        35\n",
      "          28       0.88      0.74      0.81        31\n",
      "          29       0.00      0.00      0.00        81\n",
      "          30       0.00      0.00      0.00         9\n",
      "          31       0.00      0.00      0.00        14\n",
      "          32       0.50      0.69      0.58        13\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         8\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         5\n",
      "          38       0.00      0.00      0.00       126\n",
      "          39       0.28      0.98      0.43        42\n",
      "          40       0.45      0.87      0.59        83\n",
      "          41       0.00      0.00      0.00         5\n",
      "          42       0.00      0.00      0.00         4\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00        41\n",
      "          45       0.00      0.00      0.00         4\n",
      "          46       0.00      0.00      0.00        65\n",
      "          47       1.00      0.17      0.29        12\n",
      "          48       0.37      0.85      0.52        40\n",
      "          49       0.00      0.00      0.00         4\n",
      "          50       0.00      0.00      0.00        47\n",
      "          51       0.00      0.00      0.00         7\n",
      "          52       0.62      0.80      0.70        10\n",
      "          53       0.50      0.75      0.60         4\n",
      "          54       0.55      0.75      0.63         8\n",
      "          55       0.59      0.95      0.73        21\n",
      "          56       0.29      0.67      0.40         3\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       0.57      0.67      0.62         6\n",
      "          59       0.33      0.14      0.20         7\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.38      0.95      0.54       123\n",
      "          62       0.82      0.61      0.70        23\n",
      "          63       0.28      0.93      0.43        98\n",
      "          64       0.67      0.89      0.76        38\n",
      "          65       0.00      0.00      0.00        17\n",
      "          66       0.33      0.07      0.12        14\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.45      0.59      0.51        17\n",
      "          69       0.32      0.98      0.49        42\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         3\n",
      "          72       0.25      0.99      0.40       177\n",
      "          73       1.00      0.42      0.59        19\n",
      "          74       0.40      0.57      0.47         7\n",
      "          75       0.00      0.00      0.00         4\n",
      "          76       0.96      0.99      0.97        77\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.37      0.96      0.54       104\n",
      "          79       0.53      0.95      0.68        37\n",
      "          80       0.68      0.83      0.75        18\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.39      0.09      0.14       169\n",
      "          83       0.33      0.99      0.50        95\n",
      "          84       0.19      1.00      0.32        76\n",
      "          85       0.67      0.12      0.20       256\n",
      "          86       0.41      1.00      0.58       151\n",
      "          87       0.26      0.94      0.41        32\n",
      "          88       0.52      0.97      0.67        59\n",
      "          89       0.00      0.00      0.00        88\n",
      "          90       0.00      0.00      0.00        21\n",
      "          91       0.00      0.00      0.00         5\n",
      "          92       0.00      0.00      0.00        87\n",
      "          93       0.00      0.00      0.00         6\n",
      "          94       0.00      0.00      0.00         8\n",
      "          95       0.50      0.03      0.05        35\n",
      "          96       0.00      0.00      0.00        19\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00        12\n",
      "          99       0.43      0.02      0.04       138\n",
      "         100       0.00      0.00      0.00        70\n",
      "\n",
      "   micro avg       0.39      0.39      0.39      7456\n",
      "   macro avg       0.27      0.33      0.25      7456\n",
      "weighted avg       0.46      0.39      0.34      7456\n",
      " samples avg       0.36      0.36      0.36      7456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yt_, yp_ = y_predict(validation_loader, model, 6)\n",
    "print(classification_report(yt_, yp_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yt, yp = y_predict(test_loader, model, 6)\n",
    "print(classification_report(yt[:,:-2], yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = classification_report(yt, yp, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repdf = pd.DataFrame.from_dict(rep, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,20))\n",
    "plt.barh(y = repdf.index, width = repdf[\"f1-score\"])\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt[:,:-2].shape, yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"y_true\": yt, \"y_pred\": yp}, \"../saved_models/swiki_test_predictions.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def s_cut_threshold_predict(data, model):\n",
    "    logging.info(\"Evaluating ...\")\n",
    "    yy_t = []\n",
    "    yy_p = []\n",
    "    with torch.no_grad():\n",
    "        for index, (doc_vec, labs, yin, y01) in enumerate(tqdm(data)):\n",
    "            \n",
    "            \n",
    "            W_params = list(model.parameters())[0].data.squeeze()\n",
    "            \n",
    "            score = model.linear.forward(doc_vec)\n",
    "#             score = F.softmax(score)\n",
    "            score = score.detach().numpy()\n",
    "            y_index = np.argmax(score, 1)\n",
    "            \n",
    "            sc = torch.from_numpy(score)\n",
    "            sorted_, indices  = torch.sort(sc)\n",
    "            mid = (sorted_[1:] + sorted_[:-1])/2\n",
    "            best_thresh, best_f1 = sorted_[0], 0\n",
    "            y_true = y01\n",
    "            y_true = y_true.numpy()\n",
    "            \n",
    "            for threshold in mid:\n",
    "                y_pred = np.array(sc > threshold).astype(int)\n",
    "                f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "\n",
    "                if f1 > best_f1:\n",
    "                    best_thresh = threshold\n",
    "                    best_f1 = f1\n",
    "            \n",
    "            y_pred = np.array(sc > best_thresh).astype(int)\n",
    "            \n",
    "            yy_t.append(y_true)\n",
    "            yy_p.append(y_pred)\n",
    "            \n",
    "    yy_t = np.vstack(yy_t)\n",
    "    yy_p = np.vstack(yy_p)\n",
    "    return yy_t, yy_p\n",
    "\n",
    "y1, y2 = s_cut_threshold_predict(validation_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y1, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.iter.MLbin.inverse_transform(yp)[:5] #scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod = nn.Linear(20, 5) # predict logits for 5 classes\n",
    "x = torch.randn(1, 20)\n",
    "y = torch.Tensor([[1., 0., 1., 0., 0.]]) # get classA and classC as active\n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "optimize = torch.optim.SGD(mod.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimize.zero_grad()\n",
    "    output = mod(x)\n",
    "    print(output.data.squeeze())\n",
    "    los = criterio(output, y)\n",
    "    los.backward()\n",
    "    optimize.step()\n",
    "    print('Loss: {:.3f}'.format(los.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor([1, 1, -1])\n",
    "u = torch.FloatTensor([1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y * u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log2(1+torch.exp(y * u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(1, 2), (1, 3), (2, 4) -> edge list\n",
    "inititalize a matrix of parameters of size: num_classes x num_components.\n",
    "assume num_classes = 4, num_components = 5\n",
    "\n",
    "after this, i create a W_pi(n) which is a matrix that has the respective w_pi(n) representation for each n,\n",
    "i.e. at each row\n",
    "\n",
    "after this, my aim is to keep updating W in ($%^) such that their eucledian distance minimizes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.35985602 -0.09033231  0.35838661 -0.11806976]\n",
      " [ 0.23111327 -0.67067624 -1.2447228  -0.10620869]\n",
      " [ 0.22060692 -0.16869103  0.2035156   0.77664249]\n",
      " [ 0.77283405  0.85737137  1.00532603  0.49708194]\n",
      " [ 0.35632583  1.94296143  0.78361983 -0.845167  ]] \n",
      "---\n",
      " [[-1.35985602 -0.09033231  0.35838661 -0.11806976]\n",
      " [ 0.23111327 -0.67067624 -1.2447228  -0.10620869]\n",
      " [ 0.22060692 -0.16869103  0.2035156   0.77664249]\n",
      " [ 0.77283405  0.85737137  1.00532603  0.49708194]\n",
      " [ 0.35632583  1.94296143  0.78361983 -0.845167  ]]\n",
      "^^^^^^^^^^^^^^^^^^^^\n",
      "no func\n",
      " [[5.23420072 7.10877193 2.68368733 2.38147902]\n",
      " [5.23420072 7.10877193 2.68368733 2.38147902]\n",
      " [5.23420072 7.10877193 2.68368733 2.38147902]\n",
      " [5.23420072 7.10877193 2.68368733 2.38147902]\n",
      " [5.23420072 7.10877193 2.68368733 2.38147902]]\n",
      "no func\n",
      " [5.23420072 7.10877193 2.68368733 2.38147902]\n",
      "^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(5,4)\n",
    "W_pi = W\n",
    "W_ans = np.zeros_like(W)\n",
    "print(W,'\\n---\\n', W_pi)\n",
    "print(\"^\"*20)\n",
    "for i in range(1):\n",
    "    W_ans[:,0] = 0.5*np.linalg.norm(W[:, 0] - W_pi[:, 1], 2)**2 + 0.5*np.linalg.norm(W[:, 0] - W_pi[:, 2], 2)**2\n",
    "    W_ans[:,1] = 0.5*np.linalg.norm(W[:, 1] - W_pi[:, 0], 2)**2 + 0.5*np.linalg.norm(W[:, 1] - W_pi[:, 3], 2)**2\n",
    "    W_ans[:,2] = 0.5*np.linalg.norm(W[:, 2] - W_pi[:, 0], 2)**2\n",
    "    W_ans[:,3] = 0.5*np.linalg.norm(W[:, 3] - W_pi[:, 2], 2)**2\n",
    "    print(\"no func\\n\", (W_ans))\n",
    "    print(\"no func\\n\", np.mean(W_ans, axis=0))\n",
    "    print(\"^\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(0,1),\n",
    "        (0,2),\n",
    "        (1,3)]\n",
    "vertices = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ig.Graph(n=4, edges=edges, directed=True, vertex_attrs={\"name\": vertices})\n",
    "g.vs[\"label\"] = g.vs[\"name\"]\n",
    "y = g.layout(\"kk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#($%^)#\n",
    "np.linalg.norm(W-W_pi, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
