{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from scripts.src.hierarchy import *\n",
    "from scripts.src.processing import *\n",
    "from scripts.src.label_utils import *\n",
    "from scripts.src.data_reading import *\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "logging.basicConfig(level=logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and num_gpus > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_data(y):\n",
    "\n",
    "    class_labels = np.unique(y)\n",
    "    num_tasks = len(class_labels)\n",
    "    num_examples = y.shape[0]\n",
    "    if num_tasks == 1:\n",
    "        raise ValueError(\"The number of classes has to be greater than one.\")\n",
    "    elif num_tasks == 2:\n",
    "        if 1 in class_labels and -1 in class_labels:\n",
    "            num_tasks = 1\n",
    "            class_labels = np.array([-1, 1])\n",
    "        elif 1 in class_labels and 0 in class_labels:\n",
    "            num_tasks = 1\n",
    "            class_labels = np.array([0, 1])\n",
    "        else:\n",
    "            raise ValueError(\"Unable to decide postive label\")\n",
    "\n",
    "    lbin = LabelBinarizer(neg_label=-1, pos_label=1)\n",
    "    lbin.fit(class_labels)\n",
    "    y_bin = lbin.transform(y)\n",
    "    return y_bin, class_labels, num_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    def __init__(self, datafile, catfile, subsample, is_directed, fmt):\n",
    "        self.datafile = datafile\n",
    "        \n",
    "        if fmt == \"libsvm\":\n",
    "            self.lib_data = LIBSVM_Reader(self.datafile, True, n_components, subsample)\n",
    "            self.df = self.lib_data.data_df\n",
    "            self.MLmatrix = self.lib_data.label_matrix\n",
    "            self.MLbin = self.lib_data.binarizer\n",
    "            self.rev_df = self.lib_data.rev_df\n",
    "        elif fmt ==\"raw\":\n",
    "            self.raw_df = CSV_Reader(self.datafile, subsample)\n",
    "            self.df = self.raw_df.data_df\n",
    "            self.rev_df = self.raw_df.rev_df\n",
    "        \n",
    "        self.cat = HierarchyUtils(catfile, [n_components,1], is_directed, False)\n",
    "#         self.wn = self.cat.generate_vectors(device = device, neighbours = True)\n",
    "\n",
    "    def read_df(self, idx):\n",
    "        i = self.df.index[self.df[\"doc_id\"] == idx][0]\n",
    "        return self.df.at[i, \"doc_vector\"], self.df.at[i, \"doc_labels\"], i\n",
    "    \n",
    "    def __getitem__(self, _id):\n",
    "        return self.read_df(_id)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _id in self.df.index:\n",
    "            yield self[_id]\n",
    "\n",
    "class DatasetModule(Dataset):\n",
    "\n",
    "    def __init__(self, root_location, cat_file, subsample, is_directed, fmt):\n",
    "        \n",
    "        self.iter = DatasetIterator(root_location, cat_file, subsample, is_directed, fmt)\n",
    "        \n",
    "        class_labels = self.iter.MLbin.classes_\n",
    "        temp = {}\n",
    "        for j, i in enumerate(list(class_labels)):\n",
    "            if i not in temp:\n",
    "                temp[i] = j\n",
    "\n",
    "        self.small_mapper = temp\n",
    "        \n",
    "        self.lmbda = self.lambda_param()\n",
    "        \n",
    "    def lambda_param(self):\n",
    "        wn = self.iter.cat.generate_vectors(device = device, neighbours=True)\n",
    "        w_n = list2tensor(wn[0].values())\n",
    "        w_pi = list2tensor(wn[1].values())\n",
    "\n",
    "        norm2 = torch.norm(w_n-w_pi, 2)\n",
    "        lmbda = 0.5*norm2**2\n",
    "        return lmbda\n",
    "\n",
    "    def encode_labels(self, labels, idx):\n",
    "        for each_label in labels:\n",
    "            if each_label in self.iter.cat.T_leaves:\n",
    "                y = self.iter.MLmatrix[idx].toarray().flatten()\n",
    "                y_in, _, _ = _check_data(y)\n",
    "                y_in = y_in.flatten()\n",
    "                break\n",
    "            else:\n",
    "                y_in = np.ones((len(self.small_mapper),))*-1\n",
    "        y_in = torch.as_tensor(y_in, dtype=torch.float32, device=device)\n",
    "        return y_in\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.iter.df)\n",
    "\n",
    "    def __load(self, idx):\n",
    "        doc_vec, doc_labels, doc_id = self.iter[idx]\n",
    "        yin = self.encode_labels(doc_labels, idx)\n",
    "        return doc_vec, doc_labels, doc_id, yin\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.__load(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = DatasetModule(\"../rcv1.tar/RCV1_1/rcv1.train.ltc.svm\", \"../rcv1.tar/RCV1_1/rcv1.topic.hierarchy\", False, False, \"libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DatasetModule(\"../rcv1.tar/RCV1_1/rcv1.test.ltc.svm\", \"../rcv1.tar/RCV1_1/rcv1.topic.hierarchy\", 0.2, False, \"libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DatasetModule(\"../swiki/data/train_remapped.txt\", \"../swiki/data/cat_hier.txt\", False, True, \"libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = DatasetModule(\"../swiki/data/test_remapped.txt\", \"../swiki/data/cat_hier.txt\", False, False, \"libsvm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 99\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "doc_vec, doc_labels, _id, yy =  train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 300])\n",
      "**************************************************\n",
      "tensor([10, 10,  5, 71, 95,  5, 71, 99, 35, 71, 96,  5,  5,  5, 99,  5, 71, 71,\n",
      "        19, 28,  5,  5,  2, 71, 35, 71, 99, 71, 22,  5, 31, 94, 71, 59,  3, 15,\n",
      "        34,  2, 71,  1])\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
      "         1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1.])\n",
      "--------------------------------------------------\n",
      "__________________________________________________\n",
      "tensor([ 6736,  5844,  3337, 18878,  9493, 12201, 22161, 10656, 13453, 19755,\n",
      "        20177,  3313,  7810, 13713, 13076, 19540, 18017, 13450, 15386,  5449,\n",
      "        17159, 15793,  6323, 17962,  8987,  4553, 16332, 21406,  6495,  4545,\n",
      "        14931, 18734, 12272,  6395,  3064, 19465,  1914, 16291,  2975,  2735])\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "print(doc_vec.shape)\n",
    "print(\"*\"*50)\n",
    "print(doc_labels[0])\n",
    "print(\"~\"*50)\n",
    "print(yy[0])\n",
    "print(\"-\"*50)\n",
    "# print(yy[1][0])\n",
    "print(\"_\"*50)\n",
    "print(_id)\n",
    "print(\"^\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda\n",
    "torch.backends.cudnn.version()\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(nn.Module):\n",
    "    def __init__(self, weight_dims):\n",
    "        super().__init__()\n",
    "        w_n = torch.FloatTensor(*weight_dims)\n",
    "\n",
    "        weights_n = nn.init.xavier_normal_(w_n, gain = nn.init.calculate_gain('relu'))\n",
    "        weights_pi = torch.Tensor([nn.init.random.random()*1e-2])\n",
    "        \n",
    "        self.w = nn.Parameter(weights_n)    \n",
    "        self.w_pi = nn.Parameter(weights_pi) + self.w\n",
    "        \n",
    "    def forward(self, x_i):\n",
    "        tanh = torch.tanh(x_i.matmul(self.w))\n",
    "        return tanh\n",
    "    \n",
    "    def L2_reg(self):\n",
    "        norm = torch.norm((self.w-self.w_pi), 2)\n",
    "        sol = 0.5*norm**2\n",
    "        return sol\n",
    "    \n",
    "class HRLR(nn.Module):\n",
    "    def __init__(self, n_components, num_tasks):\n",
    "        super().__init__()\n",
    "        self.linear = Node([n_components, num_tasks])\n",
    "\n",
    "    def forward(self, yin, x_i):\n",
    "        # for each node, compute forward, and do a -1 +1 threshold to get classes\n",
    "        score = self.linear.forward(x_i)\n",
    "        self.fwd_pass = - yin * score\n",
    "        return self.fwd_pass\n",
    "    \n",
    "    def compute_loss_leaf(self):\n",
    "        loss = torch.log2(1+torch.exp(self.fwd_pass))\n",
    "        l2_reg = self.linear.L2_reg()\n",
    "        value = loss.mean()\n",
    "        return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entire_model(model, path):\n",
    "    torch.save(model, path)\n",
    "\n",
    "def save_model_state(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model():\n",
    "    '''\n",
    "    training performance is affected by large `n_tasks` size which basically increases the number of parameters to tune.\n",
    "    as parameter dimension increases, weight decay also needs to be increased. what is the relation between param dim \n",
    "    and weight decay?\n",
    "    '''\n",
    "\n",
    "    # Hyper Parameters \n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.001 \n",
    "    n_tasks = len(train_data.iter.MLbin.classes_) #batch_size\n",
    "\n",
    "    model = HRLR(n_components, n_tasks)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=model.linear.L2_reg().item())\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, optimizer, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, num_epochs = reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9715e-02, -1.9600e-02, -1.8655e-02,  ..., -1.9813e-02,\n",
       "         -1.9029e-02, -1.2243e-02],\n",
       "        [-6.5944e-04, -1.2343e-03, -3.9871e-04,  ..., -1.1730e-03,\n",
       "          3.7422e-04, -2.2475e-03],\n",
       "        [ 2.4277e-03,  2.7103e-03,  2.5467e-03,  ...,  1.6826e-03,\n",
       "          2.2863e-03,  1.1948e-03],\n",
       "        ...,\n",
       "        [ 4.7320e-05,  1.0373e-04,  6.9379e-05,  ...,  3.5816e-05,\n",
       "          1.4818e-04,  4.2904e-04],\n",
       "        [-1.7985e-04, -1.1426e-04, -4.1487e-04,  ..., -1.0698e-04,\n",
       "         -8.1758e-05, -3.7880e-04],\n",
       "        [-8.7251e-05, -2.1085e-04, -1.2022e-04,  ..., -1.7656e-04,\n",
       "         -1.5752e-04, -2.9808e-04]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = optimizer.param_groups[0][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = {\n",
    "    \"test_f1\": [],\n",
    "    \"loss\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 463/463 [01:05<00:00,  7.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 463/463 [01:06<00:00,  7.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 463/463 [01:10<00:00,  7.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 463/463 [01:11<00:00,  7.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 463/463 [01:05<00:00,  7.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    for j, (doc_vec, doc_labels, _id, yin) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        if torch.isnan(list(model.parameters())[0].data.sum()):\n",
    "            logging.info(\"oh we got some nans...!\")\n",
    "            model, optimizer, num_epochs = reset_model()\n",
    "            continue\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(yin, doc_vec)\n",
    "            loss = model.compute_loss_leaf()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            monitor[\"loss\"].append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(monitor[\"loss\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor[\"loss\"][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entire_model(model, \"../saved_models/swiki_full-model_lr-{}_bs-{}_lmbda-{}.pth\".format(1e-3, batch_size, wd))\n",
    "save_model_state(model, \"../saved_models/swiki_model-state_lr-{}_bs-{}_lmbda-{}.pth\".format(1e-3, batch_size, wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Predicting for validation model...\n",
      "  0%|                                                                                          | 0/116 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 300])\n",
      "torch.Size([40])\n",
      "torch.Size([40, 101])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
       "        33, 33, 33, 33])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def y_predict(data, model):\n",
    "    logging.info(\"Predicting for validation model...\")\n",
    "    with torch.no_grad():\n",
    "        for index, (doc_vec, label_ids, doc_id, y_true) in enumerate(tqdm(data)):\n",
    "\n",
    "            print(doc_vec.shape)\n",
    "            \n",
    "            score = model.linear.forward(doc_vec)\n",
    "            print(score[0])            \n",
    "            y_index = np.argmax(score, 1)\n",
    "\n",
    "            break\n",
    "    return y_index\n",
    "\n",
    "y_predict(validation_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating ...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:20<00:00,  6.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def gather_outputs(data, model):\n",
    "    logging.info(\"Evaluating ...\")\n",
    "    yy_t = []\n",
    "    yy_p = []\n",
    "    with torch.no_grad():\n",
    "        for index, (doc_vec, label_ids, doc_id, yin) in enumerate(tqdm(data)):\n",
    "            \n",
    "            \n",
    "            W_params = list(model.parameters())[0].data.squeeze()\n",
    "            \n",
    "            score = model.linear.forward(doc_vec)\n",
    "            score = score.detach().numpy()\n",
    "            y_index = np.argmax(score, 1)\n",
    "            \n",
    "            sc = torch.sigmoid(torch.from_numpy(score))\n",
    "            sorted_, indices  = torch.sort(sc)\n",
    "            mid = (sorted_[1:] + sorted_[:-1])/2\n",
    "            best_thresh, best_f1 = sorted_[0], 0\n",
    "            y_true = torch.where(yin > 0, torch.Tensor([1]), torch.Tensor([0])).int()\n",
    "            y_true = y_true.numpy()\n",
    "\n",
    "            for threshold in mid:\n",
    "                y_pred = np.array(sc > threshold).astype(int)\n",
    "                f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "\n",
    "                if f1 > best_f1:\n",
    "                    best_thresh = threshold\n",
    "                    best_f1 = f1\n",
    "            \n",
    "            y_pred = np.array(sc > best_thresh).astype(int)\n",
    "            \n",
    "            yy_t.append(y_true)\n",
    "            yy_p.append(y_pred)\n",
    "            \n",
    "    yy_t = np.vstack(yy_t)\n",
    "    yy_p = np.vstack(yy_p)\n",
    "    return yy_t, yy_p\n",
    "\n",
    "y1, y2 = gather_outputs(validation_loader, model)\n",
    "# f1_score(y1, y2, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.20      0.06       129\n",
      "           1       0.02      0.23      0.04        73\n",
      "           2       0.03      0.16      0.05       153\n",
      "           3       0.00      0.10      0.01        31\n",
      "           4       0.17      0.39      0.23       736\n",
      "           5       0.09      0.22      0.13       410\n",
      "           6       0.02      0.19      0.04        72\n",
      "           7       0.08      0.21      0.11       347\n",
      "           8       0.00      0.12      0.00         8\n",
      "           9       0.04      0.16      0.07       206\n",
      "          10       0.02      0.13      0.03        75\n",
      "          11       0.01      0.10      0.02        48\n",
      "          12       0.00      0.08      0.00        13\n",
      "          13       0.02      0.20      0.03        46\n",
      "          14       0.06      0.20      0.09       244\n",
      "          15       0.05      0.16      0.07       206\n",
      "          16       0.01      0.24      0.02        25\n",
      "          17       0.01      0.13      0.01        30\n",
      "          18       0.03      0.12      0.05       153\n",
      "          19       0.02      0.21      0.03        38\n",
      "          20       0.00      0.12      0.01        17\n",
      "          21       0.04      0.13      0.06       156\n",
      "          22       0.04      0.12      0.06       198\n",
      "          23       0.00      0.10      0.01        20\n",
      "          24       0.01      0.12      0.02        41\n",
      "          25       0.00      0.00      0.00         9\n",
      "          26       0.00      0.20      0.01         5\n",
      "          27       0.02      0.12      0.03        81\n",
      "          28       0.00      0.20      0.00         5\n",
      "          29       0.00      0.10      0.01        20\n",
      "          30       0.01      0.13      0.03        55\n",
      "          31       0.01      0.12      0.02        49\n",
      "          32       0.01      0.14      0.03        51\n",
      "          33       0.41      1.00      0.58      1879\n",
      "          34       0.00      0.00      0.00        39\n",
      "          35       0.03      0.12      0.05       129\n",
      "          36       0.00      0.18      0.01        11\n",
      "          37       0.00      0.06      0.01        34\n",
      "          38       0.01      0.09      0.01        33\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.01      0.31      0.02        13\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.12      0.00         8\n",
      "          44       0.07      0.15      0.09       212\n",
      "          45       0.02      0.15      0.04        67\n",
      "          46       0.05      0.18      0.08       142\n",
      "          47       0.00      0.00      0.00        12\n",
      "          48       0.00      0.00      0.00         9\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.02      0.14      0.04        65\n",
      "          51       0.00      0.00      0.00         4\n",
      "          52       0.00      0.02      0.01       102\n",
      "          53       0.00      0.00      0.00        17\n",
      "          54       0.01      0.05      0.01        62\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         4\n",
      "          57       0.01      0.17      0.02        29\n",
      "          58       0.12      0.22      0.16       566\n",
      "          59       0.01      0.08      0.02        74\n",
      "          60       0.01      0.15      0.01        13\n",
      "          61       0.00      0.12      0.01         8\n",
      "          62       0.00      0.11      0.01         9\n",
      "          63       0.01      0.09      0.02        35\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00        11\n",
      "          67       0.00      0.00      0.00        13\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.28      0.52      0.37      1176\n",
      "          70       0.06      0.17      0.08       192\n",
      "          71       0.01      0.13      0.02        38\n",
      "          72       0.04      0.10      0.06       165\n",
      "          73       0.01      0.05      0.01        44\n",
      "          74       0.01      0.09      0.01        23\n",
      "          75       0.01      0.06      0.01        31\n",
      "          76       0.00      1.00      0.01         1\n",
      "          77       0.00      0.00      0.00        35\n",
      "          78       0.02      0.08      0.03        66\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       0.00      0.11      0.01         9\n",
      "          81       0.06      0.09      0.07       274\n",
      "          82       0.01      0.05      0.01        37\n",
      "          83       0.01      0.12      0.02        16\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       0.04      0.08      0.05       152\n",
      "          86       0.00      0.00      0.00         2\n",
      "          87       0.03      0.04      0.03       184\n",
      "          88       0.01      0.04      0.01        57\n",
      "          89       0.00      0.04      0.01        25\n",
      "          90       0.00      0.00      0.00         9\n",
      "          91       0.06      0.08      0.07       228\n",
      "          92       0.02      0.05      0.03       118\n",
      "          93       0.07      0.06      0.07       289\n",
      "          94       0.03      0.05      0.04       156\n",
      "          95       0.02      0.03      0.02       136\n",
      "          96       0.13      0.08      0.10       440\n",
      "          97       0.07      0.04      0.05       260\n",
      "          98       0.03      0.05      0.04        55\n",
      "          99       0.06      0.04      0.05       101\n",
      "         100       0.26      0.01      0.02      1033\n",
      "\n",
      "   micro avg       0.07      0.30      0.12     12723\n",
      "   macro avg       0.03      0.12      0.04     12723\n",
      "weighted avg       0.15      0.30      0.17     12723\n",
      " samples avg       0.30      0.26      0.19     12723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22.0, 34.0, 71.0, 77.0), (), (94.0, 103.0), (15.0, 16.0, 34.0), (71.0, 84.0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iter.lib_data.binarizer.inverse_transform(y1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.0, 6.0, 34.0, 71.0), (34.0,), (5.0, 34.0), (34.0,), (34.0, 71.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iter.MLbin.inverse_transform(y2)[:5] #scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2298,  0.3665, -0.4045,  0.7686,  0.4514])\n",
      "Loss: 0.897\n",
      "tensor([ 0.4765,  0.0375, -0.0704,  0.3880,  0.1110])\n",
      "Loss: 0.716\n",
      "tensor([ 0.6899, -0.2463,  0.2180,  0.0561, -0.1830])\n",
      "Loss: 0.580\n",
      "tensor([ 0.8760, -0.4907,  0.4663, -0.2303, -0.4362])\n",
      "Loss: 0.479\n",
      "tensor([ 1.0398, -0.7023,  0.6811, -0.4769, -0.6549])\n",
      "Loss: 0.403\n",
      "tensor([ 1.1853, -0.8869,  0.8683, -0.6903, -0.8454])\n",
      "Loss: 0.345\n",
      "tensor([ 1.3157, -1.0494,  1.0330, -0.8764, -1.0128])\n",
      "Loss: 0.300\n",
      "tensor([ 1.4336, -1.1939,  1.1792, -1.0401, -1.1612])\n",
      "Loss: 0.264\n",
      "tensor([ 1.5408, -1.3235,  1.3103, -1.1856, -1.2940])\n",
      "Loss: 0.236\n",
      "tensor([ 1.6391, -1.4406,  1.4286, -1.3160, -1.4139])\n",
      "Loss: 0.212\n"
     ]
    }
   ],
   "source": [
    "mod = nn.Linear(20, 5) # predict logits for 5 classes\n",
    "x = torch.randn(1, 20)\n",
    "y = torch.Tensor([[1., 0., 1., 0., 0.]]) # get classA and classC as active\n",
    "\n",
    "criterio = nn.BCEWithLogitsLoss()\n",
    "optimize = torch.optim.SGD(mod.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    optimize.zero_grad()\n",
    "    output = mod(x)\n",
    "    print(output.data.squeeze())\n",
    "    los = criterio(output, y)\n",
    "    los.backward()\n",
    "    optimize.step()\n",
    "    print('Loss: {:.3f}'.format(los.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
