{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from collections import OrderedDict, Counter, defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.utils import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../../Starspace/data/oms/text/oms-prep.tsv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val = df[df[\"used_as\"]==\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract    Highlightsâ€¢Regional regression models of perce...\n",
       "file_id                       EVISE.PII:S2214-5818(17)30315-4\n",
       "label_id                               [189126970, 170590667]\n",
       "labels                         ['Geology', 'Aquatic Science']\n",
       "used_as                                            validation\n",
       "doc_len                                                    34\n",
       "doc         highlightsregion percentil flow creat basin de...\n",
       "Name: 583635, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.iloc[99504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_graphml(\"../../../Starspace/data/oms/cat_hier_TREE_INT.graphml\", node_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189720899]\n"
     ]
    }
   ],
   "source": [
    "print(list(graph.predecessors(257778730)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_graph = graph.to_undirected()\n",
    "nod = [250232503,253033933,\n",
    "252578107,189721083,\n",
    "210628467,249133392,\n",
    "248811484,249672056,\n",
    "189721148,253230766,\n",
    "209895092]\n",
    "par = [250232503, 252578107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250232503 0\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "250232503 9\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n",
      "no path\n"
     ]
    }
   ],
   "source": [
    "for p in par:\n",
    "    for n in nod:\n",
    "        try:\n",
    "            p = nx.shortest_path_length(un_graph, n, p)\n",
    "            print(n, p)\n",
    "        except:\n",
    "            print(\"no path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_preprocess(text):\n",
    "    first = text.encode('ascii', 'ignore').decode('utf-8').lower()\n",
    "    second = preprocessing.remove_stopwords(first)\n",
    "    third = preprocessing.strip_punctuation(second)\n",
    "    fourth =preprocessing.strip_short(preprocessing.strip_numeric(third))\n",
    "    return fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fopen = open(\"../../../Starspace/data/oms/text/oms-all_raw.txt\", \"rb\")\n",
    "file = fopen.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80d12d6ec9247588417081bb676c05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=583933), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_docs = []\n",
    "for line in tqdm(file):\n",
    "    preprocessed1 = document_preprocess(line.decode(\"utf-8\"))\n",
    "    list_of_docs.append(preprocessed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8a04bc0509481ea9994470c1d0644d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=583933), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "word_count = Counter()\n",
    "\n",
    "for doc in tqdm(list_of_docs):\n",
    "    words = list(tokenize(doc))\n",
    "    for word in words:\n",
    "        vocabulary.append(word)\n",
    "        word_count[word]+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd86b4cc920d42368917ed97f62d4270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=364521), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# A storage to store tokens after subsampling\n",
    "new_tokens = {}\n",
    "\n",
    "# tokens is a list of word indexes from original text\n",
    "for word in tqdm(unique_tokens):\n",
    "    frac = word_count[word]/len(unique_tokens)\n",
    "    prob = (np.sqrt(frac/0.001) + 1) * (0.001/frac)\n",
    "    \n",
    "    if prob > 0.2 :\n",
    "        new_tokens[word]=prob\n",
    "        \n",
    "unique_words = list(new_tokens.keys())\n",
    "corpus_specific_stopwords = set(unique_tokens).difference(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim, analyze, drug, theories, variable, volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'achieved',\n",
       " 'acid',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'age',\n",
       " 'agreement',\n",
       " 'aim',\n",
       " 'algebra',\n",
       " 'algebraic',\n",
       " 'algebras',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'alpha',\n",
       " 'alternative',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analytical',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'and',\n",
       " 'anti',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'approximation',\n",
       " 'arbitrary',\n",
       " 'area',\n",
       " 'article',\n",
       " 'assessed',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'asymptotic',\n",
       " 'atoms',\n",
       " 'available',\n",
       " 'average',\n",
       " 'background',\n",
       " 'band',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basis',\n",
       " 'beam',\n",
       " 'behavior',\n",
       " 'best',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'binary',\n",
       " 'binding',\n",
       " 'black',\n",
       " 'blood',\n",
       " 'body',\n",
       " 'bound',\n",
       " 'boundary',\n",
       " 'bounded',\n",
       " 'bounds',\n",
       " 'brain',\n",
       " 'calculated',\n",
       " 'calculations',\n",
       " 'called',\n",
       " 'cancer',\n",
       " 'capacity',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'category',\n",
       " 'cell',\n",
       " 'cells',\n",
       " 'central',\n",
       " 'certain',\n",
       " 'chain',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'channel',\n",
       " 'characteristic',\n",
       " 'characteristics',\n",
       " 'characterized',\n",
       " 'charge',\n",
       " 'chemical',\n",
       " 'children',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classical',\n",
       " 'classification',\n",
       " 'clinical',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'cluster',\n",
       " 'clusters',\n",
       " 'code',\n",
       " 'coefficients',\n",
       " 'combination',\n",
       " 'combined',\n",
       " 'common',\n",
       " 'communication',\n",
       " 'compact',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparison',\n",
       " 'complete',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'component',\n",
       " 'components',\n",
       " 'computational',\n",
       " 'compute',\n",
       " 'computing',\n",
       " 'concentration',\n",
       " 'concentrations',\n",
       " 'concept',\n",
       " 'conclusion',\n",
       " 'conclusions',\n",
       " 'condition',\n",
       " 'conditions',\n",
       " 'conducted',\n",
       " 'conjecture',\n",
       " 'connected',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'consistent',\n",
       " 'constant',\n",
       " 'constraints',\n",
       " 'construct',\n",
       " 'constructed',\n",
       " 'construction',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continuous',\n",
       " 'contrast',\n",
       " 'control',\n",
       " 'convergence',\n",
       " 'convex',\n",
       " 'core',\n",
       " 'correlated',\n",
       " 'correlation',\n",
       " 'correlations',\n",
       " 'corresponding',\n",
       " 'cost',\n",
       " 'coupled',\n",
       " 'coupling',\n",
       " 'critical',\n",
       " 'cross',\n",
       " 'current',\n",
       " 'curve',\n",
       " 'curves',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'day',\n",
       " 'days',\n",
       " 'decay',\n",
       " 'decreased',\n",
       " 'define',\n",
       " 'defined',\n",
       " 'degree',\n",
       " 'delta',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'density',\n",
       " 'dependence',\n",
       " 'dependent',\n",
       " 'derive',\n",
       " 'derived',\n",
       " 'described',\n",
       " 'description',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'detected',\n",
       " 'detection',\n",
       " 'determine',\n",
       " 'determined',\n",
       " 'develop',\n",
       " 'developed',\n",
       " 'development',\n",
       " 'difference',\n",
       " 'differences',\n",
       " 'different',\n",
       " 'differential',\n",
       " 'diffusion',\n",
       " 'dimension',\n",
       " 'dimensional',\n",
       " 'dimensions',\n",
       " 'direct',\n",
       " 'directly',\n",
       " 'discrete',\n",
       " 'discuss',\n",
       " 'discussed',\n",
       " 'disease',\n",
       " 'disorder',\n",
       " 'distance',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'distributions',\n",
       " 'dna',\n",
       " 'domain',\n",
       " 'dose',\n",
       " 'double',\n",
       " 'driven',\n",
       " 'drug',\n",
       " 'dual',\n",
       " 'dynamic',\n",
       " 'dynamical',\n",
       " 'dynamics',\n",
       " 'early',\n",
       " 'edge',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'electron',\n",
       " 'electronic',\n",
       " 'elements',\n",
       " 'emission',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'enhanced',\n",
       " 'entropy',\n",
       " 'environment',\n",
       " 'equation',\n",
       " 'equations',\n",
       " 'equilibrium',\n",
       " 'equivalent',\n",
       " 'error',\n",
       " 'especially',\n",
       " 'establish',\n",
       " 'established',\n",
       " 'estimate',\n",
       " 'estimates',\n",
       " 'estimation',\n",
       " 'evaluate',\n",
       " 'evaluated',\n",
       " 'evaluation',\n",
       " 'events',\n",
       " 'evidence',\n",
       " 'evolution',\n",
       " 'exact',\n",
       " 'example',\n",
       " 'examples',\n",
       " 'existence',\n",
       " 'existing',\n",
       " 'expansion',\n",
       " 'expected',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experiments',\n",
       " 'explicit',\n",
       " 'explore',\n",
       " 'exposure',\n",
       " 'expression',\n",
       " 'extend',\n",
       " 'extended',\n",
       " 'extension',\n",
       " 'external',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'factors',\n",
       " 'family',\n",
       " 'fast',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'field',\n",
       " 'fields',\n",
       " 'finally',\n",
       " 'findings',\n",
       " 'finite',\n",
       " 'first',\n",
       " 'fixed',\n",
       " 'flow',\n",
       " 'fluctuations',\n",
       " 'fluid',\n",
       " 'flux',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'force',\n",
       " 'form',\n",
       " 'formation',\n",
       " 'forms',\n",
       " 'formula',\n",
       " 'fraction',\n",
       " 'framework',\n",
       " 'free',\n",
       " 'frequency',\n",
       " 'fully',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'functions',\n",
       " 'fundamental',\n",
       " 'furthermore',\n",
       " 'future',\n",
       " 'galaxies',\n",
       " 'galaxy',\n",
       " 'gamma',\n",
       " 'gap',\n",
       " 'gas',\n",
       " 'gauge',\n",
       " 'gaussian',\n",
       " 'gene',\n",
       " 'general',\n",
       " 'generalized',\n",
       " 'generated',\n",
       " 'generation',\n",
       " 'genes',\n",
       " 'geometric',\n",
       " 'geometry',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'global',\n",
       " 'good',\n",
       " 'graph',\n",
       " 'graphs',\n",
       " 'greater',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'growth',\n",
       " 'having',\n",
       " 'health',\n",
       " 'heat',\n",
       " 'here',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'however',\n",
       " 'human',\n",
       " 'identified',\n",
       " 'identify',\n",
       " 'image',\n",
       " 'images',\n",
       " 'imaging',\n",
       " 'impact',\n",
       " 'implementation',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'include',\n",
       " 'included',\n",
       " 'including',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'increases',\n",
       " 'increasing',\n",
       " 'independent',\n",
       " 'index',\n",
       " 'indicate',\n",
       " 'individual',\n",
       " 'induced',\n",
       " 'infinite',\n",
       " 'influence',\n",
       " 'information',\n",
       " 'infty',\n",
       " 'initial',\n",
       " 'input',\n",
       " 'integral',\n",
       " 'interaction',\n",
       " 'interactions',\n",
       " 'interval',\n",
       " 'introduce',\n",
       " 'introduced',\n",
       " 'invariant',\n",
       " 'investigate',\n",
       " 'investigated',\n",
       " 'key',\n",
       " 'knowledge',\n",
       " 'known',\n",
       " 'lambda',\n",
       " 'language',\n",
       " 'large',\n",
       " 'larger',\n",
       " 'laser',\n",
       " 'lattice',\n",
       " 'law',\n",
       " 'layer',\n",
       " 'lead',\n",
       " 'leading',\n",
       " 'leads',\n",
       " 'learning',\n",
       " 'left',\n",
       " 'length',\n",
       " 'let',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'limit',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'linear',\n",
       " 'lines',\n",
       " 'liquid',\n",
       " 'literature',\n",
       " 'local',\n",
       " 'log',\n",
       " 'long',\n",
       " 'loss',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'magnetic',\n",
       " 'magnitude',\n",
       " 'main',\n",
       " 'major',\n",
       " 'management',\n",
       " 'manifold',\n",
       " 'manifolds',\n",
       " 'map',\n",
       " 'maps',\n",
       " 'mass',\n",
       " 'material',\n",
       " 'materials',\n",
       " 'mathbb',\n",
       " 'mathcal',\n",
       " 'matrices',\n",
       " 'matrix',\n",
       " 'matter',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'measure',\n",
       " 'measured',\n",
       " 'measurement',\n",
       " 'measurements',\n",
       " 'measures',\n",
       " 'mechanism',\n",
       " 'mechanisms',\n",
       " 'medium',\n",
       " 'memory',\n",
       " 'method',\n",
       " 'methods',\n",
       " 'metric',\n",
       " 'mice',\n",
       " 'minimal',\n",
       " 'minimum',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'modes',\n",
       " 'modified',\n",
       " 'molecular',\n",
       " 'momentum',\n",
       " 'months',\n",
       " 'moreover',\n",
       " 'motion',\n",
       " 'multi',\n",
       " 'multiple',\n",
       " 'natural',\n",
       " 'nature',\n",
       " 'near',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'negative',\n",
       " 'network',\n",
       " 'networks',\n",
       " 'neural',\n",
       " 'new',\n",
       " 'nodes',\n",
       " 'noise',\n",
       " 'non',\n",
       " 'nonlinear',\n",
       " 'normal',\n",
       " 'notion',\n",
       " 'novel',\n",
       " 'nuclear',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'numerical',\n",
       " 'objective',\n",
       " 'objects',\n",
       " 'observations',\n",
       " 'observed',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'omega',\n",
       " 'one',\n",
       " 'open',\n",
       " 'operator',\n",
       " 'operators',\n",
       " 'optical',\n",
       " 'optimal',\n",
       " 'optimization',\n",
       " 'order',\n",
       " 'outcomes',\n",
       " 'overall',\n",
       " 'pair',\n",
       " 'paper',\n",
       " 'parallel',\n",
       " 'parameter',\n",
       " 'parameters',\n",
       " 'partial',\n",
       " 'participants',\n",
       " 'particle',\n",
       " 'particles',\n",
       " 'particular',\n",
       " 'path',\n",
       " 'patient',\n",
       " 'patients',\n",
       " 'pattern',\n",
       " 'patterns',\n",
       " 'performance',\n",
       " 'performed',\n",
       " 'period',\n",
       " 'periodic',\n",
       " 'phase',\n",
       " 'physical',\n",
       " 'physics',\n",
       " 'plane',\n",
       " 'plasma',\n",
       " 'point',\n",
       " 'points',\n",
       " 'polynomial',\n",
       " 'population',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'pre',\n",
       " 'predicted',\n",
       " 'presence',\n",
       " 'present',\n",
       " 'presented',\n",
       " 'pressure',\n",
       " 'previous',\n",
       " 'previously',\n",
       " 'primary',\n",
       " 'probability',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'procedure',\n",
       " 'process',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'produced',\n",
       " 'product',\n",
       " 'production',\n",
       " 'program',\n",
       " 'proof',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'propose',\n",
       " 'proposed',\n",
       " 'protein',\n",
       " 'proteins',\n",
       " 'prove',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'purpose',\n",
       " 'quality',\n",
       " 'quantum',\n",
       " 'quasi',\n",
       " 'question',\n",
       " 'radiation',\n",
       " 'radio',\n",
       " 'random',\n",
       " 'range',\n",
       " 'rank',\n",
       " 'rate',\n",
       " 'rates',\n",
       " 'ratio',\n",
       " 'ray',\n",
       " 'reaction',\n",
       " 'real',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'reduce',\n",
       " 'reduced',\n",
       " 'reduction',\n",
       " 'regime',\n",
       " 'region',\n",
       " 'regions',\n",
       " 'regression',\n",
       " 'regular',\n",
       " 'related',\n",
       " 'relation',\n",
       " 'relations',\n",
       " 'relationship',\n",
       " 'relative',\n",
       " 'relevant',\n",
       " 'report',\n",
       " 'reported',\n",
       " 'representation',\n",
       " 'required',\n",
       " 'research',\n",
       " 'resolution',\n",
       " 'resonance',\n",
       " 'respect',\n",
       " 'respectively',\n",
       " 'response',\n",
       " 'result',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'revealed',\n",
       " 'review',\n",
       " 'right',\n",
       " 'ring',\n",
       " 'risk',\n",
       " 'robust',\n",
       " 'role',\n",
       " 'sample',\n",
       " 'samples',\n",
       " 'scalar',\n",
       " 'scale',\n",
       " 'scales',\n",
       " 'scaling',\n",
       " 'scattering',\n",
       " 'scheme',\n",
       " 'search',\n",
       " 'second',\n",
       " 'selection',\n",
       " 'self',\n",
       " 'sensitivity',\n",
       " 'sequence',\n",
       " 'sequences',\n",
       " 'series',\n",
       " 'set',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'shape',\n",
       " 'short',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'shows',\n",
       " 'sigma',\n",
       " 'signal',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'simulation',\n",
       " 'simulations',\n",
       " 'single',\n",
       " 'size',\n",
       " 'small',\n",
       " 'smooth',\n",
       " 'social',\n",
       " 'software',\n",
       " 'solar',\n",
       " 'solution',\n",
       " 'solutions',\n",
       " 'source',\n",
       " 'sources',\n",
       " 'space',\n",
       " 'spaces',\n",
       " 'spatial',\n",
       " 'special',\n",
       " 'species',\n",
       " 'specific',\n",
       " 'spectra',\n",
       " 'spectral',\n",
       " 'spectrum',\n",
       " 'speed',\n",
       " 'spin',\n",
       " 'stability',\n",
       " 'stable',\n",
       " 'stage',\n",
       " 'standard',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'state',\n",
       " 'states',\n",
       " 'statistical',\n",
       " 'stellar',\n",
       " 'step',\n",
       " 'stochastic',\n",
       " 'strategies',\n",
       " 'strategy',\n",
       " 'strength',\n",
       " 'stress',\n",
       " 'strong',\n",
       " 'strongly',\n",
       " 'structural',\n",
       " 'structure',\n",
       " 'structures',\n",
       " 'studied',\n",
       " 'studies',\n",
       " 'study',\n",
       " 'sub',\n",
       " 'subset',\n",
       " 'sufficient',\n",
       " 'suggest',\n",
       " 'suitable',\n",
       " 'sum',\n",
       " 'support',\n",
       " 'surface',\n",
       " 'surfaces',\n",
       " 'surgery',\n",
       " 'survey',\n",
       " 'survival',\n",
       " 'symmetric',\n",
       " 'symmetry',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'target',\n",
       " 'task',\n",
       " 'technique',\n",
       " 'techniques',\n",
       " 'temperature',\n",
       " 'temporal',\n",
       " 'tensor',\n",
       " 'term',\n",
       " 'terms',\n",
       " 'test',\n",
       " 'tested',\n",
       " 'tests',\n",
       " 'that',\n",
       " 'the',\n",
       " 'theorem',\n",
       " 'theoretical',\n",
       " 'theories',\n",
       " 'theory',\n",
       " 'therapy',\n",
       " 'thermal',\n",
       " 'three',\n",
       " 'threshold',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tissue',\n",
       " 'tool',\n",
       " 'topological',\n",
       " 'total',\n",
       " 'transfer',\n",
       " 'transition',\n",
       " 'transport',\n",
       " 'treated',\n",
       " 'treatment',\n",
       " 'tree',\n",
       " 'tumor',\n",
       " 'two',\n",
       " 'type',\n",
       " 'types',\n",
       " 'underlying',\n",
       " 'understanding',\n",
       " 'unique',\n",
       " 'unit',\n",
       " 'universal',\n",
       " 'upper',\n",
       " 'use',\n",
       " 'useful',\n",
       " 'user',\n",
       " 'users',\n",
       " 'value',\n",
       " 'values',\n",
       " 'variable',\n",
       " 'variables',\n",
       " 'variety',\n",
       " 'vector',\n",
       " 'velocity',\n",
       " 'version',\n",
       " 'volume',\n",
       " 'water',\n",
       " 'wave',\n",
       " 'waves',\n",
       " 'way',\n",
       " 'weak',\n",
       " 'weight',\n",
       " 'well',\n",
       " 'wide',\n",
       " 'women',\n",
       " 'work',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years',\n",
       " 'zero'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_specific_stopwordss_specific_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import *\n",
    "snow = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3771afc60f64f14ba5c330cfd00973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=583933), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated_doc_list = []\n",
    "for doc in tqdm(list_of_docs):\n",
    "    string = \"\"\n",
    "    for word in doc.split(\" \"):\n",
    "        if word not in corpus_specific_stopwords:\n",
    "            word = snow.stem(word)\n",
    "            string+=\"{} \".format(word)\n",
    "            \n",
    "    updated_doc_list.append(preprocessing.strip_multiple_whitespaces(string))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fopen = open(\"../../../Starspace/data/oms/text/oms-all_raw_preprocessed.txt\", \"w+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in updated_doc_list:\n",
    "    fopen.write(\"{}\\n\".format(doc))\n",
    "    \n",
    "fopen.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
