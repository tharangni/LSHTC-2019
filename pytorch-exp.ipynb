{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader/data\n",
    "# https://discuss.pytorch.org/t/runtimeerror-multi-target-not-supported-newbie/10216/4\n",
    "\n",
    "# Build the Dataset. We are going to generate a simple data set and then we will read it.\n",
    "# Build the DataLoader.\n",
    "# Build the model.\n",
    "# Define the loss function and the optimizer.\n",
    "# Train the model.\n",
    "# Generate predictions.\n",
    "# Plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import collections, gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from scripts.utils.hierarchy import *\n",
    "from scripts.utils.processing import *\n",
    "from scripts.utils.data_reading import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16 # wn vector size  --> ~log_{2}(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() and num_gpus > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65333it [00:00, 239454.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# N, T_leaves & PI_parents have to be present globally! (list of all the labels)\n",
    "# one_hot_labels because I will keep accessing it for each document <1082>\n",
    "p2c_table, c2p_table, node2id, id2node, PI_parents, T_leaves, N = lookup_table(\"swiki/data/cat_hier.txt\", subset = False)\n",
    "graph_obj = hierarchy2graph(p2c_table, node2id)\n",
    "node2vec = hierarchy_vectors(graph_obj, id2node, p2c_table, n, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50312/50312 [00:00<00:00, 210219.94it/s]\n"
     ]
    }
   ],
   "source": [
    "order_mapping = generate_order_mapping(N)\n",
    "binary_yin = generate_binary_yin(N, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def too_hot_mapping(label):\n",
    "\n",
    "    # order_mapping, wn_tensors & binary_yin HAVE TO BE A GLOBAL OBJECT\n",
    "    \n",
    "#     doc_labels = list(map(int, list(label)))\n",
    "    y_in = []\n",
    "    \n",
    "    try:\n",
    "        w_n = node2vec[label]\n",
    "        if label in c2p_table:\n",
    "            pi_n = c2p_table[label][0]\n",
    "            w_pi = node2vec[pi_n]\n",
    "        if label in T_leaves:\n",
    "            int_rep = order_mapping[label]\n",
    "            y_in = binary_yin[int_rep-1]\n",
    "            \n",
    "    except:\n",
    "        print(\"wait whaat?\")\n",
    "    \n",
    "    return w_n, w_pi, y_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_non_leaf_wn(label_id):\n",
    "    '''\n",
    "    accepts label ids only which are non-leaf nodes\n",
    "    '''\n",
    "    \n",
    "    assert label_id in N, \"{} is not a node\".format(label_id)    \n",
    "\n",
    "    C_ids = p2c_table[label_id]\n",
    "    Cn = len(C_ids)\n",
    "\n",
    "    w_n = node2vec[label_id]\n",
    "    w_pi = node2vec[c2p_table[label_id][0]]\n",
    "    sum_wc = 0.0\n",
    "\n",
    "    for idx in C_ids:\n",
    "        w_c = node2vec[idx]\n",
    "        sum_wc += w_c\n",
    "\n",
    "    Wn = 1/(Cn +1) * (w_pi + sum_wc)\n",
    "\n",
    "    return Wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSWIKI(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, reduce = True, n_components = 128):\n",
    "        self.reduce = reduce\n",
    "        self.n_components = n_components\n",
    "        self.data, self.labels = lower_dim(file_path, reduce, n_components)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.reduce:\n",
    "            document = torch.as_tensor(self.data[index], device = device, dtype = torch.float32)\n",
    "        else:\n",
    "            document = torch.as_tensor(self.data[index].todense(), device = device, dtype = torch.float32)\n",
    "\n",
    "        label = torch.as_tensor(self.labels[index], device = device, dtype = torch.float32)\n",
    "        \n",
    "        w_n, w_pi, y_in = too_hot_mapping(int(label))\n",
    "        \n",
    "        l2_reg = nn.parameter.Parameter((0.5*torch.sqrt(torch.sum((w_n-w_pi)**2))**2).to(device))\n",
    "        \n",
    "#         self.w_n[label] = w_n\n",
    "        \n",
    "        return document, label, w_n, w_pi, y_in, l2_reg\n",
    "    \n",
    "#     def update_wn(self, label_id):\n",
    "        \n",
    "#         self.w_n[label_id] = update_non_leaf_wn(label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = DatasetSWIKI(\"swiki/data/train_split_remapped.txt\", reduce=False, n_components = n_components)\n",
    "valid_data = DatasetSWIKI(\"swiki/data/valid_remapped.txt\", reduce=False, n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590035,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs shape on batch size = torch.Size([199, 1, 2085164]), torch.float32, cuda:0\n",
      "label shape on batch size = torch.Size([199]), torch.float32, cuda:0\n",
      "w_n shape on batch size = torch.Size([199, 16]), torch.float32, cuda:0\n",
      "w_pi shape on batch size = torch.Size([199, 16]), torch.float32, cuda:0\n",
      "y_in shape on batch size = torch.Size([199, 16]), torch.float32, cuda:0\n",
      "l2-reg shape on batch size = torch.Size([199]), torch.float32, cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "\n",
    "doc, labs, w_n, w_pi, y_in, l2 = train_iter.next()\n",
    "\n",
    "print('docs shape on batch size = {}, {}, {}'.format(doc.shape, doc.dtype, doc.device))\n",
    "print('label shape on batch size = {}, {}, {}'.format(labs.shape, labs.dtype, labs.device))\n",
    "print('w_n shape on batch size = {}, {}, {}'.format(w_n.shape, w_n.dtype, w_n.device))\n",
    "print('w_pi shape on batch size = {}, {}, {}'.format(w_pi.shape, w_pi.dtype, w_pi.device))\n",
    "print('y_in shape on batch size = {}, {}, {}'.format(y_in.shape, y_in.dtype, y_in.device))\n",
    "print('l2-reg shape on batch size = {}, {}, {}'.format(l2.shape, l2.dtype, l2.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2085164)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "# input_size = train_data.data.shape[1] #128 n_components\n",
    "input_size = train_data.data[0].shape[1] #2085164 \n",
    "\n",
    "num_classes = n #50312 --> n (16)\n",
    "num_epochs = 10 # TRAIN IT FOR A LOT OF EPOCHS in case of lbfgs (2nd order method) else less is more\n",
    "learning_rate = 1e-4 #1e-4, 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, num_classes, False)\n",
    "        \n",
    "    def forward(self, x, wn):\n",
    "        x1 = self.linear1(x)\n",
    "        y =  torch.mul(-x1, wn)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SoftMarginLoss(reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2965"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"batch_{}_train_valid_model.pt\".format(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    losses = checkpoint['losses']\n",
    "    step = checkpoint['step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], step:[100/2965], loss: 0.684947\n",
      "Epoch [1/10], step:[200/2965], loss: 0.681258\n",
      "Epoch [1/10], step:[300/2965], loss: 0.678774\n",
      "Epoch [1/10], step:[400/2965], loss: 0.673325\n",
      "Epoch [1/10], step:[500/2965], loss: 0.671472\n",
      "Epoch [1/10], step:[600/2965], loss: 0.667838\n",
      "Epoch [1/10], step:[700/2965], loss: 0.671404\n",
      "Epoch [1/10], step:[800/2965], loss: 0.667230\n",
      "Epoch [1/10], step:[900/2965], loss: 0.670128\n",
      "Epoch [1/10], step:[1000/2965], loss: 0.663459\n",
      "Epoch [1/10], step:[1100/2965], loss: 0.662757\n",
      "Epoch [1/10], step:[1200/2965], loss: 0.663248\n",
      "Epoch [1/10], step:[1300/2965], loss: 0.668458\n",
      "Epoch [1/10], step:[1400/2965], loss: 0.669680\n",
      "Epoch [1/10], step:[1500/2965], loss: 0.670203\n",
      "Epoch [1/10], step:[1600/2965], loss: 0.666799\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    train_iter = iter(train_loader)\n",
    "    for step, (document, _, labels, _, y_ins, l2_reg) in enumerate(train_iter):\n",
    "\n",
    "        document = document.reshape(batch_size,-1)\n",
    "   \n",
    "        optimizer.zero_grad()\n",
    "        w_xi = model(document, labels)\n",
    "        loss1 = criterion(w_xi, y_ins) + torch.mean(l2_reg)\n",
    "\n",
    "        if (step+1) % 100 == 0: \n",
    "            print ('Epoch [{}/{}], step:[{}/{}], loss: {:.6f}'.format(epoch+1, num_epochs, step+1, total_step, loss1.item()))\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        losses.append(loss1.item())\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         if type(optimizer) != torch.optim.LBFGS:\n",
    "#         else:\n",
    "#             def closure():               \n",
    "#                 optimizer.zero_grad()\n",
    "#                 w_xi = model(document, labels)\n",
    "#                 loss1 = criterion(w_xi, y_ins) + l2_reg\n",
    "                \n",
    "#                 if (step+1) % 100 == 0: \n",
    "#                     print ('Epoch [{}/{}], step:[{}/{}], loss: {:.6f}'.format(epoch+1, num_epochs, step+1, total_step, loss1.item()))\n",
    "#                     torch.cuda.empty_cache()\n",
    "                \n",
    "#                 losses.append(loss1.item())\n",
    "#                 loss1.backward()\n",
    "#                 return loss1\n",
    "#             optimizer.step(closure)\n",
    "\n",
    "    torch.save({\n",
    "    'epoch': epoch,\n",
    "    'step': step,\n",
    "    'losses': losses,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss1}, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umm = []\n",
    "for v in l2:\n",
    "    umm.append(v.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(umm));"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'train_vaild_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for document, all_labels, labels, pis, y_ins in valid_data:\n",
    "        \n",
    "        document = Variable(document).float().to(device) \n",
    "        \n",
    "        labels = Variable(labels).float().to(device).view(-1, n)\n",
    "        pis = pis.view(-1, n)\n",
    "        y_ins = y_ins.view(-1, n)\n",
    "        \n",
    "        output = model(document, labels)\n",
    "\n",
    "        \n",
    "        print(torch.sum(torch.where(outputs>0.0001, torch.tensor(1), torch.tensor(0)), dim=0))\n",
    "        print(torch.sum(torch.where(labels>0, torch.tensor(1), torch.tensor(0)), dim=0))\n",
    "\n",
    "        umm, predicted = torch.max(outputs.data, 1)\n",
    "        print(umm.shape)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'test_valid_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import umap # fit should get a sparse matrix\n",
    "%time trans = umap.UMAP(n_neighbors=5, random_state=42, n_components=32, verbose=True).fit(train_data.data)\n",
    "trans.embedding_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
