{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader/data\n",
    "# https://discuss.pytorch.org/t/runtimeerror-multi-target-not-supported-newbie/10216/4\n",
    "\n",
    "# Build the Dataset. We are going to generate a simple data set and then we will read it.\n",
    "# Build the DataLoader.\n",
    "# Build the model.\n",
    "# Define the loss function and the optimizer.\n",
    "# Train the model.\n",
    "# Generate predictions.\n",
    "# Plot the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import collections, gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing, metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# from scripts.utils.logger import Logger\n",
    "from scripts.utils.data_reading import lower_dim, rr_reader\n",
    "from scripts.utils.processing import lookup_table, generate_label_vector\n",
    "\n",
    "logging.basicConfig(level=logging.INFO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65333it [00:00, 235908.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# N, T_leaves & PI_parents have to be present globally! (list of all the labels)\n",
    "# one_hot_labels because I will keep accessing it for each document <1082>\n",
    "p2c_table, c2p_table, _, _, PI_parents, T_leaves, N = lookup_table(\"swiki/data/cat_hier.txt\", subset = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\" if (torch.cuda.is_available() and num_gpus > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order_label_mapping = generate_label_vector(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def too_hot_mapping(label_tuple):\n",
    "\n",
    "    # order_label_mapping HAS TO BE A GLOBAL OBJECT\n",
    "    # y_in = {-1, +1}\n",
    "    \n",
    "    doc_labels = list(map(int, list(label_tuple)))\n",
    "    \n",
    "    temp_y_in = torch.ones((len(N),), device = device)*-1\n",
    "    \n",
    "    temp_wn = torch.zeros((len(N),), device = device, requires_grad=True)\n",
    "    temp_w_pi_n = torch.zeros((len(N),), device = device)\n",
    "    \n",
    "    try:\n",
    "        for label in doc_labels:\n",
    "            int_rep = order_label_mapping[label]\n",
    "            temp_wn[int_rep-1] += 1\n",
    "            if label in T_leaves:\n",
    "                temp_y_in[int_rep-1] += 2\n",
    "                if label in c2p_table:\n",
    "                    temp_w_pi_n[order_label_mapping[c2p_table[label][0]]-1] += 1 \n",
    "                    # todo: think of a way to return w_n and w_pi_n and then compute MSE exclusively\n",
    "                    # for them in training\n",
    "    except:\n",
    "        print(\"wait whaat?\")\n",
    "    return temp_wn, temp_y_in, temp_w_pi_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSWIKI(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, reduce = True, n_components = 128):\n",
    "        self.reduce = reduce\n",
    "        self.n_components = n_components\n",
    "        self.data, self.labels = lower_dim(file_path, reduce, n_components)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.reduce:\n",
    "            document = torch.from_numpy(self.data[index]).to(device)\n",
    "        else:\n",
    "            document = torch.from_numpy(self.data[index].todense()).to(device)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        \n",
    "        label_vector, y_in, pi = too_hot_mapping(label)        \n",
    "        \n",
    "        return document, label, label_vector, y_in, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Elapsed time: 3.0min 40.45sec\n",
      "INFO:root:Elapsed time: 2.0min 46.69sec\n"
     ]
    }
   ],
   "source": [
    "train_data = DatasetSWIKI(\"swiki/data/train_split_remapped.txt\", reduce=True, n_components = n_components)\n",
    "valid_data = DatasetSWIKI(\"swiki/data/valid_remapped.txt\", reduce=True, n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle = False)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs shape on batch size = torch.Size([32, 128])\n",
      "labels shape on batch size = torch.Size([32, 50312])\n",
      "y_in shape on batch size = torch.Size([32, 50312])\n",
      "out shape on batch size = torch.Size([32, 50312])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "\n",
    "doc, labbbs, labs, y, pi = train_iter.next()\n",
    "\n",
    "print('docs shape on batch size = {}'.format(doc.shape))\n",
    "print('labels shape on batch size = {}'.format(labs.shape))\n",
    "print('y_in shape on batch size = {}'.format(y.shape))\n",
    "print('out shape on batch size = {}'.format(pi.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19060.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "208516400/10940\n",
    "# 2085164/547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = train_data.data.shape[1] #2085164 -> 128\n",
    "\n",
    "num_classes = len(N) #50312\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, batch_size, False)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x1 = self.linear1(x)  \n",
    "        x1 = F.softmax(x1, dim=0)\n",
    "        return x1.mm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear1): Linear(in_features=128, out_features=32, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.SoftMarginLoss(reduction='mean') \n",
    "L2Loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()-torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], step:[100/9995], loss: 0.701836\n",
      "Epoch [1/10], step:[200/9995], loss: 0.701126\n",
      "Epoch [1/10], step:[300/9995], loss: 0.701698\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_iter = iter(train_loader)\n",
    "    for i, (document, _, labels, y_in, pi) in enumerate(train_iter):\n",
    "        \n",
    "        document = Variable(document).float().to(device) # batch size 100\n",
    "        labels = Variable(labels).float().to(device)\n",
    "\n",
    "        if type(optimizer) != torch.optim.LBFGS:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            w_xi = model(document, labels)\n",
    "            loss1 = criterion(w_xi, y_in)\n",
    "            loss2 = L2Loss(labels, pi)\n",
    "            loss_full = torch.sqrt(loss2) + loss1\n",
    "\n",
    "            if (i+1) % 100 == 0: \n",
    "                print ('Epoch [{}/{}], step:[{}/{}], loss: {:.6f}'.format(epoch+1, num_epochs, i+1, total_step, loss_full.item()))\n",
    "                torch.cuda.empty_cache()\n",
    " \n",
    "            losses.append(loss_full.item())\n",
    "            loss_full.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        else:\n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                w_xi = model(document, labels)\n",
    "                loss1 = criterion(w_xi, y_in)\n",
    "                loss2 = L2Loss(labels, pi)\n",
    "                loss_full = torch.sqrt(loss2) + loss1\n",
    "                if (i+1) % 100 == 0: \n",
    "                    print ('Epoch [{}/{}], step:[{}/{}], loss: {:.6f}'.format(epoch+1, num_epochs, i+1, total_step, loss_full.item()))\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                losses.append(loss_full.item())\n",
    "                loss_full.backward()\n",
    "                return loss_full\n",
    "\n",
    "            optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.t().mm(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[-469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'train_small_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for documents, _, labels in valid_data:\n",
    "        docs = Variable(torch.from_numpy(documents)).float()\n",
    "        outputs = model(docs)\n",
    "        print(torch.sum(torch.where(outputs>0.0001, torch.tensor(1), torch.tensor(0)), dim=0))\n",
    "        print(torch.sum(torch.where(labels>0, torch.tensor(1), torch.tensor(0)), dim=0))\n",
    "\n",
    "        umm, predicted = torch.max(outputs.data, 1)\n",
    "        print(umm.shape)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'train_valid_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "c1 = plt.Circle((0.2, 0.5), 0.2, color='r')\n",
    "c2 = plt.Circle((0.8, 0.5), 0.2, color='r')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_patch(c1)\n",
    "ax.add_patch(c2)\n",
    "plt.axis('scaled')\n",
    "\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter()\n",
    "writer.add_figure('matplotlib', fig)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #         Forward + Backward + Optimize\n",
    "#         def closure():\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(document)\n",
    "#             loss = criterion(outputs, torch.max(labels, 1)[0])\n",
    "# #             print('loss:', loss.item())\n",
    "#             loss.backward()\n",
    "#             return loss\n",
    "#         optimizer.step(closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import umap # fit should get a sparse matrix\n",
    "%time trans = umap.UMAP(n_neighbors=5, random_state=42, n_components=32, verbose=True).fit(train_data.data)\n",
    "trans.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "167593,441685 160318:1 227881:1 255720:1 265934:1 432905:2 515946:1 538188:1 586136:1 610561:1 692683:1 \n",
    "                                        735075:1 828325:1 874107:1 898766:1 1087064:1 1354716:1 1432746:1 \n",
    "                                        1454292:1 1463839:1 1626714:1 1715083:1 1839104:1 1864180:1 2023750:1 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
